# Architecture: Separated DA Posting and ZK Batching

## Key Insight

We've separated two distinct concerns that have different requirements:

| Concern         | Frequency          | Purpose                              | Cost               |
| --------------- | ------------------ | ------------------------------------ | ------------------ |
| **DA Posting**  | Every sample (30s) | Create detailed, replayable history  | Low (just storage) |
| **ZK Batching** | Every 5-10 min     | Prove uptime over meaningful windows | High (computation) |

## Why This Design?

### DA Posting: Frequent & Detailed

```
Every 30 seconds â†’ Post sample to Celestia DA

Benefits:
âœ… Detailed history - every sample recorded
âœ… Replayable - anyone can verify each check
âœ… Real-time visibility - see issues immediately
âœ… Low cost - just append data to DA layer
```

### ZK Batching: Infrequent & Aggregated

```
Every 5-10 minutes â†’ Generate ZK proof of batch

Benefits:
âœ… Amortize proof cost over many samples
âœ… Prove uptime over meaningful time window
âœ… Smaller proof size than individual proofs
âœ… Suitable for on-chain verification
```

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   DAS Node      â”‚
â”‚  (OTLP Export)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Every ~15s
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    da-reader                               â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  SAMPLING (Every 30s)                               â”‚  â”‚
â”‚  â”‚  âœ“ Check head/headers advancing                     â”‚  â”‚
â”‚  â”‚  âœ“ Generate sample bit (0 or 1)                     â”‚  â”‚
â”‚  â”‚  âœ“ Save to samples.json                             â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                     â”‚                                      â”‚
â”‚                     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                     â”‚                 â”‚                   â”‚
â”‚                     â–¼                 â–¼                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  DA POSTING (Every 30s)  â”‚  â”‚ BATCHING (5-10 min) â”‚   â”‚
â”‚  â”‚  Post each sample to DA  â”‚  â”‚ Aggregate samples   â”‚   â”‚
â”‚  â”‚  for detailed history    â”‚  â”‚ for ZK proof        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚             â”‚                             â”‚               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚                             â”‚
              â–¼                             â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Celestia DA     â”‚         â”‚  ZK Proof Gen    â”‚
    â”‚  (Every sample)  â”‚         â”‚  (Every batch)   â”‚
    â”‚  â”€ Sample bits   â”‚         â”‚  â”€ Batch proof   â”‚
    â”‚  â”€ Timestamps    â”‚         â”‚  â”€ Bitmap hash   â”‚
    â”‚  â”€ Head/Headers  â”‚         â”‚  â”€ Threshold     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Configuration

### In `config.toml`:

```toml
[sampling]
tick_secs = 30          # Sample health every 30 seconds
max_staleness_secs = 120
grace_period_secs = 45

[da_posting]
enabled = false         # Enable when ready
post_every_sample = true # Post each sample (recommended for detailed history)

[batching]
window_secs = 600       # 10 minutes = 20 samples per batch
                        # Balance between proof cost and time resolution
```

### Tuning Guide

#### Sampling Interval (`tick_secs`)

```
15s: Very frequent, detailed (80 samples/batch @ 10min)
30s: Recommended - aligns with ~5 Celestia blocks âœ…
60s: Less frequent (10 samples/batch @ 10min)
```

#### Batching Window (`window_secs`)

```
300s  (5 min):  10 samples - Quick proofs, frequent verification
600s  (10 min): 20 samples - Good balance âœ…
900s  (15 min): 30 samples - Longer windows, fewer proofs
1800s (30 min): 60 samples - Even longer windows
```

**Trade-offs:**

- **Shorter windows**: More proofs, higher cost, faster feedback
- **Longer windows**: Fewer proofs, lower cost, slower feedback

## Example Timeline

```
Time    | Sampling          | DA Posting                | Batching
--------|-------------------|---------------------------|------------------
00:00   | Sample #1 âœ…      | Post sample #1 to DA      |
00:30   | Sample #2 âœ…      | Post sample #2 to DA      |
01:00   | Sample #3 âœ…      | Post sample #3 to DA      |
...     | ...               | ...                       |
09:30   | Sample #19 âœ…     | Post sample #19 to DA     |
10:00   | Sample #20 âœ…     | Post sample #20 to DA     | Generate batch #1
        |                   |                           | (20 samples)
        |                   |                           | Create ZK proof
10:30   | Sample #21 âœ…     | Post sample #21 to DA     |
...     | ...               | ...                       |
20:00   | Sample #40 âœ…     | Post sample #40 to DA     | Generate batch #2
        |                   |                           | (20 samples)
```

## What Gets Posted Where

### Celestia DA (Every Sample)

```json
{
  "type": "sample",
  "timestamp": 1729785600,
  "ok": true,
  "head": 8549695,
  "headers": 8549717,
  "reason": "+2 blocks"
}
```

**Size**: ~100-200 bytes per sample  
**Frequency**: Every 30 seconds  
**Purpose**: Detailed, replayable history

### ZK Proof (Every Batch)

```json
{
  "type": "batch",
  "window": {
    "start": 1729785600,
    "end": 1729786200
  },
  "n": 20,
  "good": 19,
  "threshold": 19,
  "bitmap_hash": "a1b2c3d4...",
  "proof": "0x..."
}
```

**Size**: ~1-2 KB per batch  
**Frequency**: Every 5-10 minutes  
**Purpose**: Provable uptime attestation

## Benefits of This Architecture

### 1. **Detailed History**

Every check is recorded on DA â†’ anyone can replay and verify

### 2. **Cost-Effective Proofs**

Aggregate 20 samples â†’ generate 1 proof (amortized cost)

### 3. **Real-Time Visibility**

Samples posted every 30s â†’ see issues immediately

### 4. **Flexible Verification**

- Quick check: Look at DA samples
- Cryptographic proof: Verify ZK proof
- Full audit: Replay entire history

### 5. **Aligned with Celestia**

30s samples = ~5 Celestia blocks  
Detailed enough to catch block-level issues

## Implementation Status

| Component           | Status             | Notes                                |
| ------------------- | ------------------ | ------------------------------------ |
| Sampling            | âœ… Implemented     | Working with 30s interval            |
| Ring buffer         | âœ… Implemented     | Stores samples for batching          |
| Batch generation    | âœ… Implemented     | Creates batches every 10 min         |
| File output         | âœ… Implemented     | samples.json, batch.json, bitmap.hex |
| DA posting          | âŒ Not implemented | Placeholder in code                  |
| ZK proof generation | âŒ Not implemented | Planned (arkworks)                   |
| Batch signing       | âŒ Not implemented | Planned (ed25519)                    |

## Next Steps

### Phase 1: DA Posting (Current Priority)

```rust
// After each sample:
if config.da_posting.enabled {
    post_sample_to_celestia_da(&sample).await;
}
```

**Implementation:**

- Connect to Celestia light node API
- Format sample as blob
- Post to namespace `0x2N1CE`
- Handle errors/retries

### Phase 2: ZK Proof Generation

```rust
// After each batch:
if config.proofs.enabled && meets_threshold {
    let proof = generate_zk_proof(&batch).await;
    verify_proof(&proof, &public_inputs);
}
```

**Implementation:**

- Use arkworks (Groth16 + BN254)
- Prove: Î£ bits â‰¥ threshold
- Verify locally first
- Post proof + public inputs to DA

### Phase 3: End-to-End Flow

```
Sample â†’ DA â†’ Batch â†’ ZK Proof â†’ DA â†’ Verifiable Receipt
```

## Cost Analysis

Assuming Celestia DA costs and 30s sampling:

### Per Hour

- Samples: 120 samples Ã— ~150 bytes = 18 KB
- Batches: 6 batches Ã— ~2 KB = 12 KB
- **Total**: ~30 KB/hour

### Per Day

- Samples: 2,880 samples Ã— ~150 bytes = 432 KB
- Batches: 144 batches Ã— ~2 KB = 288 KB
- **Total**: ~720 KB/day

Very affordable for Celestia DA! ğŸ’°

## Summary

This architecture **separates concerns**:

- DA posting = detailed history (frequent, cheap)
- ZK batching = proof generation (infrequent, expensive)

This gives you both:

1. **Transparency** - every check is recorded
2. **Efficiency** - proofs are generated over batches
3. **Flexibility** - tune frequencies independently
